Lmod has detected the following error: The following module(s) are unknown:
"cuda/12.2"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore_cache load "cuda/12.2"

Also make sure that all modulefiles written in TCL start with the string
#%Module



=== Python & CUDA Environment ===
Python 3.9.21
/blue/ufdatastudios/sivarama.swamyna/specialdirs/tml/venv/bin/python
PyTorch: 2.8.0+cu128
CUDA available: True
CUDA version: 12.8

Mon Nov 10 23:56:32 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.148.08             Driver Version: 570.148.08     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA B200                    On  |   00000000:52:00.0 Off |                    0 |
| N/A   36C    P0            146W / 1000W |       0MiB / 183359MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA B200                    On  |   00000000:61:00.0 Off |                    0 |
| N/A   35C    P0            149W / 1000W |       0MiB / 183359MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+

GPUs assigned: 0,1
Starting benchmark...
Benchmark initialized - Device: cuda
Output directory: ./benchmark_results

--- Loading datasets ---
Datasets loaded successfully

============================================================
STARTING FULL BENCHMARK
============================================================
Total experiments to run: 510

[1/510]

============================================================
Experiment: BASIC_ep1_none_
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9594, Val Acc: 0.8752
  Time: 82.66s

[2/510]

============================================================
Experiment: BASIC_ep1_output_perturbation_scale0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9584, Val Acc: 0.8728
  Time: 2.00s

[3/510]

============================================================
Experiment: BASIC_ep1_output_perturbation_scale0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9613, Val Acc: 0.8740
  Time: 1.50s

[4/510]

============================================================
Experiment: BASIC_ep1_output_perturbation_scale0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9583, Val Acc: 0.8720
  Time: 1.51s

[5/510]

============================================================
Experiment: BASIC_ep1_output_perturbation_scale0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9574, Val Acc: 0.8726
  Time: 1.50s

[6/510]

============================================================
Experiment: BASIC_ep1_output_perturbation_scale0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9492, Val Acc: 0.8600
  Time: 1.59s

[7/510]

============================================================
Experiment: BASIC_ep1_input_perturbation_sigma0.01
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9597, Val Acc: 0.8726
  Time: 1.51s

[8/510]

============================================================
Experiment: BASIC_ep1_input_perturbation_sigma0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9595, Val Acc: 0.8726
  Time: 1.50s

[9/510]

============================================================
Experiment: BASIC_ep1_input_perturbation_sigma0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9414, Val Acc: 0.8556
  Time: 1.49s

[10/510]

============================================================
Experiment: BASIC_ep1_input_perturbation_sigma0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8061, Val Acc: 0.7418
  Time: 1.49s

[11/510]

============================================================
Experiment: BASIC_ep1_input_perturbation_sigma0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.3419, Val Acc: 0.3376
  Time: 1.51s

[12/510]

============================================================
Experiment: BASIC_ep1_input_perturbation_sigma1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.1570, Val Acc: 0.1652
  Time: 1.57s

[13/510]

============================================================
Experiment: BASIC_ep1_test_time_augmentation_num_augmentations1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8991, Val Acc: 0.8124
  Time: 3.12s

[14/510]

============================================================
Experiment: BASIC_ep1_test_time_augmentation_num_augmentations3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9397, Val Acc: 0.8546
  Time: 2.09s

[15/510]

============================================================
Experiment: BASIC_ep1_test_time_augmentation_num_augmentations5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9446, Val Acc: 0.8590
  Time: 2.68s

[16/510]

============================================================
Experiment: BASIC_ep1_test_time_augmentation_num_augmentations7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9496, Val Acc: 0.8652
  Time: 3.26s

[17/510]

============================================================
Experiment: BASIC_ep1_test_time_augmentation_num_augmentations10
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9532, Val Acc: 0.8670
  Time: 4.12s

[18/510]

============================================================
Experiment: BASIC_ep1_temperature_scaled_temp1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9603, Val Acc: 0.8774
  Time: 1.51s

[19/510]

============================================================
Experiment: BASIC_ep1_temperature_scaled_temp1.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9604, Val Acc: 0.8728
  Time: 1.52s

[20/510]

============================================================
Experiment: BASIC_ep1_temperature_scaled_temp2.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9570, Val Acc: 0.8728
  Time: 1.58s

[21/510]

============================================================
Experiment: BASIC_ep1_temperature_scaled_temp3.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9557, Val Acc: 0.8712
  Time: 1.49s

[22/510]

============================================================
Experiment: BASIC_ep1_temperature_scaled_temp5.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9556, Val Acc: 0.8740
  Time: 1.51s

[23/510]

============================================================
Experiment: BASIC_ep1_temperature_scaled_temp10.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9597, Val Acc: 0.8738
  Time: 1.48s

[24/510]

============================================================
Experiment: BASIC_ep1_response_limited_topk_top_k1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9576, Val Acc: 0.8726
  Time: 2.77s

[25/510]

============================================================
Experiment: BASIC_ep1_response_limited_topk_top_k2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9589, Val Acc: 0.8740
  Time: 2.65s

[26/510]

============================================================
Experiment: BASIC_ep1_response_limited_topk_top_k3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9597, Val Acc: 0.8736
  Time: 1.51s

[27/510]

============================================================
Experiment: BASIC_ep1_response_limited_topk_top_k4
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9571, Val Acc: 0.8728
  Time: 1.58s

[28/510]

============================================================
Experiment: BASIC_ep1_response_limited_topk_top_k5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9583, Val Acc: 0.8716
  Time: 1.51s

[29/510]

============================================================
Experiment: BASIC_ep1_response_limited_hard_hard_labelTrue
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9578, Val Acc: 0.8736
  Time: 1.56s

[30/510]

============================================================
Experiment: BASIC_ep1_adaptive_noise_alpha0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9541, Val Acc: 0.8698
  Time: 1.51s

[31/510]

============================================================
Experiment: BASIC_ep1_adaptive_noise_alpha0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9580, Val Acc: 0.8746
  Time: 1.50s

[32/510]

============================================================
Experiment: BASIC_ep1_adaptive_noise_alpha0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9578, Val Acc: 0.8734
  Time: 1.51s

[33/510]

============================================================
Experiment: BASIC_ep1_adaptive_noise_alpha0.7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9558, Val Acc: 0.8710
  Time: 1.53s

[34/510]

============================================================
Experiment: BASIC_ep1_adaptive_noise_alpha1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9491, Val Acc: 0.8698
  Time: 1.59s

[35/510]

============================================================
Experiment: BASIC_ep3_none_
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9772, Val Acc: 0.8834
  Time: 3.18s

[36/510]

============================================================
Experiment: BASIC_ep3_output_perturbation_scale0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9780, Val Acc: 0.8834
  Time: 3.20s

[37/510]

============================================================
Experiment: BASIC_ep3_output_perturbation_scale0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9765, Val Acc: 0.8850
  Time: 3.18s

[38/510]

============================================================
Experiment: BASIC_ep3_output_perturbation_scale0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9776, Val Acc: 0.8852
  Time: 3.24s

[39/510]

============================================================
Experiment: BASIC_ep3_output_perturbation_scale0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9766, Val Acc: 0.8860
  Time: 3.19s

[40/510]

============================================================
Experiment: BASIC_ep3_output_perturbation_scale0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9698, Val Acc: 0.8740
  Time: 3.18s

[41/510]

============================================================
Experiment: BASIC_ep3_input_perturbation_sigma0.01
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9756, Val Acc: 0.8824
  Time: 3.20s

[42/510]

============================================================
Experiment: BASIC_ep3_input_perturbation_sigma0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9723, Val Acc: 0.8794
  Time: 3.26s

[43/510]

============================================================
Experiment: BASIC_ep3_input_perturbation_sigma0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9570, Val Acc: 0.8678
  Time: 3.19s

[44/510]

============================================================
Experiment: BASIC_ep3_input_perturbation_sigma0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8369, Val Acc: 0.7640
  Time: 3.17s

[45/510]

============================================================
Experiment: BASIC_ep3_input_perturbation_sigma0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.3553, Val Acc: 0.3468
  Time: 3.19s

[46/510]

============================================================
Experiment: BASIC_ep3_input_perturbation_sigma1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.1834, Val Acc: 0.1790
  Time: 3.27s

[47/510]

============================================================
Experiment: BASIC_ep3_test_time_augmentation_num_augmentations1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9349, Val Acc: 0.8490
  Time: 3.18s

[48/510]

============================================================
Experiment: BASIC_ep3_test_time_augmentation_num_augmentations3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9561, Val Acc: 0.8560
  Time: 3.75s

[49/510]

============================================================
Experiment: BASIC_ep3_test_time_augmentation_num_augmentations5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9660, Val Acc: 0.8736
  Time: 4.36s

[50/510]

============================================================
Experiment: BASIC_ep3_test_time_augmentation_num_augmentations7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9691, Val Acc: 0.8768
  Time: 5.00s

[51/510]

============================================================
Experiment: BASIC_ep3_test_time_augmentation_num_augmentations10
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9683, Val Acc: 0.8768
  Time: 5.81s

[52/510]

============================================================
Experiment: BASIC_ep3_temperature_scaled_temp1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9752, Val Acc: 0.8804
  Time: 3.19s

[53/510]

============================================================
Experiment: BASIC_ep3_temperature_scaled_temp1.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9746, Val Acc: 0.8822
  Time: 3.20s

[54/510]

============================================================
Experiment: BASIC_ep3_temperature_scaled_temp2.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9764, Val Acc: 0.8832
  Time: 3.27s

[55/510]

============================================================
Experiment: BASIC_ep3_temperature_scaled_temp3.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9786, Val Acc: 0.8854
  Time: 3.20s

[56/510]

============================================================
Experiment: BASIC_ep3_temperature_scaled_temp5.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9763, Val Acc: 0.8846
  Time: 3.18s

[57/510]

============================================================
Experiment: BASIC_ep3_temperature_scaled_temp10.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9769, Val Acc: 0.8840
  Time: 3.19s

[58/510]

============================================================
Experiment: BASIC_ep3_response_limited_topk_top_k1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9758, Val Acc: 0.8840
  Time: 3.26s

[59/510]

============================================================
Experiment: BASIC_ep3_response_limited_topk_top_k2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9767, Val Acc: 0.8874
  Time: 3.20s

[60/510]

============================================================
Experiment: BASIC_ep3_response_limited_topk_top_k3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9740, Val Acc: 0.8816
  Time: 3.20s

[61/510]

============================================================
Experiment: BASIC_ep3_response_limited_topk_top_k4
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9738, Val Acc: 0.8818
  Time: 3.20s

[62/510]

============================================================
Experiment: BASIC_ep3_response_limited_topk_top_k5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9767, Val Acc: 0.8828
  Time: 3.26s

[63/510]

============================================================
Experiment: BASIC_ep3_response_limited_hard_hard_labelTrue
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9760, Val Acc: 0.8828
  Time: 3.19s

[64/510]

============================================================
Experiment: BASIC_ep3_adaptive_noise_alpha0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9774, Val Acc: 0.8846
  Time: 3.20s

[65/510]

============================================================
Experiment: BASIC_ep3_adaptive_noise_alpha0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9740, Val Acc: 0.8812
  Time: 3.19s

[66/510]

============================================================
Experiment: BASIC_ep3_adaptive_noise_alpha0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9719, Val Acc: 0.8810
  Time: 3.26s

[67/510]

============================================================
Experiment: BASIC_ep3_adaptive_noise_alpha0.7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9737, Val Acc: 0.8826
  Time: 3.18s

[68/510]

============================================================
Experiment: BASIC_ep3_adaptive_noise_alpha1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9693, Val Acc: 0.8768
  Time: 3.18s

[69/510]

============================================================
Experiment: BASIC_ep5_none_
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9845, Val Acc: 0.8866
  Time: 4.94s

[70/510]

============================================================
Experiment: BASIC_ep5_output_perturbation_scale0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9842, Val Acc: 0.8864
  Time: 4.87s

[71/510]

============================================================
Experiment: BASIC_ep5_output_perturbation_scale0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9847, Val Acc: 0.8874
  Time: 4.91s

[72/510]

============================================================
Experiment: BASIC_ep5_output_perturbation_scale0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9851, Val Acc: 0.8840
  Time: 4.98s

[73/510]

============================================================
Experiment: BASIC_ep5_output_perturbation_scale0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9829, Val Acc: 0.8842
  Time: 4.91s

[74/510]

============================================================
Experiment: BASIC_ep5_output_perturbation_scale0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9818, Val Acc: 0.8830
  Time: 4.88s

[75/510]

============================================================
Experiment: BASIC_ep5_input_perturbation_sigma0.01
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9851, Val Acc: 0.8870
  Time: 4.97s

[76/510]

============================================================
Experiment: BASIC_ep5_input_perturbation_sigma0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9860, Val Acc: 0.8852
  Time: 4.91s

[77/510]

============================================================
Experiment: BASIC_ep5_input_perturbation_sigma0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9706, Val Acc: 0.8698
  Time: 4.91s

[78/510]

============================================================
Experiment: BASIC_ep5_input_perturbation_sigma0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8550, Val Acc: 0.7698
  Time: 4.99s

[79/510]

============================================================
Experiment: BASIC_ep5_input_perturbation_sigma0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.3322, Val Acc: 0.3222
  Time: 4.90s

[80/510]

============================================================
Experiment: BASIC_ep5_input_perturbation_sigma1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.1668, Val Acc: 0.1664
  Time: 4.92s

[81/510]

============================================================
Experiment: BASIC_ep5_test_time_augmentation_num_augmentations1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9430, Val Acc: 0.8326
  Time: 4.99s

[82/510]

============================================================
Experiment: BASIC_ep5_test_time_augmentation_num_augmentations3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9700, Val Acc: 0.8688
  Time: 5.50s

[83/510]

============================================================
Experiment: BASIC_ep5_test_time_augmentation_num_augmentations5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9756, Val Acc: 0.8702
  Time: 6.08s

[84/510]

============================================================
Experiment: BASIC_ep5_test_time_augmentation_num_augmentations7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9767, Val Acc: 0.8802
  Time: 6.72s

[85/510]

============================================================
Experiment: BASIC_ep5_test_time_augmentation_num_augmentations10
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9751, Val Acc: 0.8844
  Time: 7.51s

[86/510]

============================================================
Experiment: BASIC_ep5_temperature_scaled_temp1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9868, Val Acc: 0.8878
  Time: 4.98s

[87/510]

============================================================
Experiment: BASIC_ep5_temperature_scaled_temp1.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9867, Val Acc: 0.8912
  Time: 4.91s

[88/510]

============================================================
Experiment: BASIC_ep5_temperature_scaled_temp2.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9873, Val Acc: 0.8910
  Time: 4.90s

[89/510]

============================================================
Experiment: BASIC_ep5_temperature_scaled_temp3.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9853, Val Acc: 0.8886
  Time: 4.98s

[90/510]

============================================================
Experiment: BASIC_ep5_temperature_scaled_temp5.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9853, Val Acc: 0.8852
  Time: 4.91s

[91/510]

============================================================
Experiment: BASIC_ep5_temperature_scaled_temp10.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9866, Val Acc: 0.8878
  Time: 4.91s

[92/510]

============================================================
Experiment: BASIC_ep5_response_limited_topk_top_k1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9868, Val Acc: 0.8910
  Time: 4.97s

[93/510]

============================================================
Experiment: BASIC_ep5_response_limited_topk_top_k2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9839, Val Acc: 0.8896
  Time: 4.91s

[94/510]

============================================================
Experiment: BASIC_ep5_response_limited_topk_top_k3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9853, Val Acc: 0.8866
  Time: 4.91s

[95/510]

============================================================
Experiment: BASIC_ep5_response_limited_topk_top_k4
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9838, Val Acc: 0.8882
  Time: 4.98s

[96/510]

============================================================
Experiment: BASIC_ep5_response_limited_topk_top_k5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9835, Val Acc: 0.8842
  Time: 4.91s

[97/510]

============================================================
Experiment: BASIC_ep5_response_limited_hard_hard_labelTrue
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9855, Val Acc: 0.8884
  Time: 4.92s

[98/510]

============================================================
Experiment: BASIC_ep5_adaptive_noise_alpha0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9833, Val Acc: 0.8896
  Time: 4.99s

[99/510]

============================================================
Experiment: BASIC_ep5_adaptive_noise_alpha0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9849, Val Acc: 0.8832
  Time: 4.91s

[100/510]

============================================================
Experiment: BASIC_ep5_adaptive_noise_alpha0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9859, Val Acc: 0.8894
  Time: 4.91s

[101/510]

============================================================
Experiment: BASIC_ep5_adaptive_noise_alpha0.7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9826, Val Acc: 0.8860
  Time: 4.98s

[102/510]

============================================================
Experiment: BASIC_ep5_adaptive_noise_alpha1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9817, Val Acc: 0.8838
  Time: 4.91s

[103/510]

============================================================
Experiment: BASIC_ep7_none_
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9907, Val Acc: 0.8910
  Time: 6.66s

[104/510]

============================================================
Experiment: BASIC_ep7_output_perturbation_scale0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9909, Val Acc: 0.8870
  Time: 6.60s

[105/510]

============================================================
Experiment: BASIC_ep7_output_perturbation_scale0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9896, Val Acc: 0.8866
  Time: 6.61s

[106/510]

============================================================
Experiment: BASIC_ep7_output_perturbation_scale0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9915, Val Acc: 0.8888
  Time: 6.60s

[107/510]

============================================================
Experiment: BASIC_ep7_output_perturbation_scale0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9911, Val Acc: 0.8912
  Time: 6.56s

[108/510]

============================================================
Experiment: BASIC_ep7_output_perturbation_scale0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9889, Val Acc: 0.8842
  Time: 6.64s

[109/510]

============================================================
Experiment: BASIC_ep7_input_perturbation_sigma0.01
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9911, Val Acc: 0.8902
  Time: 6.58s

[110/510]

============================================================
Experiment: BASIC_ep7_input_perturbation_sigma0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9903, Val Acc: 0.8878
  Time: 6.64s

[111/510]

============================================================
Experiment: BASIC_ep7_input_perturbation_sigma0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9758, Val Acc: 0.8696
  Time: 6.59s

[112/510]

============================================================
Experiment: BASIC_ep7_input_perturbation_sigma0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8636, Val Acc: 0.7736
  Time: 6.67s

[113/510]

============================================================
Experiment: BASIC_ep7_input_perturbation_sigma0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.3566, Val Acc: 0.3408
  Time: 6.58s

[114/510]

============================================================
Experiment: BASIC_ep7_input_perturbation_sigma1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.1722, Val Acc: 0.1698
  Time: 6.67s

[115/510]

============================================================
Experiment: BASIC_ep7_test_time_augmentation_num_augmentations1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9490, Val Acc: 0.8446
  Time: 6.61s

[116/510]

============================================================
Experiment: BASIC_ep7_test_time_augmentation_num_augmentations3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9764, Val Acc: 0.8772
  Time: 7.26s

[117/510]

============================================================
Experiment: BASIC_ep7_test_time_augmentation_num_augmentations5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9804, Val Acc: 0.8730
  Time: 7.77s

[118/510]

============================================================
Experiment: BASIC_ep7_test_time_augmentation_num_augmentations7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9829, Val Acc: 0.8774
  Time: 8.33s

[119/510]

============================================================
Experiment: BASIC_ep7_test_time_augmentation_num_augmentations10
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9847, Val Acc: 0.8824
  Time: 9.26s

[120/510]

============================================================
Experiment: BASIC_ep7_temperature_scaled_temp1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9910, Val Acc: 0.8882
  Time: 6.55s

[121/510]

============================================================
Experiment: BASIC_ep7_temperature_scaled_temp1.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9891, Val Acc: 0.8858
  Time: 6.62s

[122/510]

============================================================
Experiment: BASIC_ep7_temperature_scaled_temp2.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9895, Val Acc: 0.8892
  Time: 6.56s

[123/510]

============================================================
Experiment: BASIC_ep7_temperature_scaled_temp3.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9910, Val Acc: 0.8872
  Time: 6.63s

[124/510]

============================================================
Experiment: BASIC_ep7_temperature_scaled_temp5.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9907, Val Acc: 0.8878
  Time: 6.55s

[125/510]

============================================================
Experiment: BASIC_ep7_temperature_scaled_temp10.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9915, Val Acc: 0.8882
  Time: 6.63s

[126/510]

============================================================
Experiment: BASIC_ep7_response_limited_topk_top_k1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9908, Val Acc: 0.8866
  Time: 6.56s

[127/510]

============================================================
Experiment: BASIC_ep7_response_limited_topk_top_k2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9903, Val Acc: 0.8912
  Time: 6.62s

[128/510]

============================================================
Experiment: BASIC_ep7_response_limited_topk_top_k3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9896, Val Acc: 0.8872
  Time: 6.56s

[129/510]

============================================================
Experiment: BASIC_ep7_response_limited_topk_top_k4
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9906, Val Acc: 0.8902
  Time: 6.55s

[130/510]

============================================================
Experiment: BASIC_ep7_response_limited_topk_top_k5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9903, Val Acc: 0.8856
  Time: 6.64s

[131/510]

============================================================
Experiment: BASIC_ep7_response_limited_hard_hard_labelTrue
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9910, Val Acc: 0.8894
  Time: 6.57s

[132/510]

============================================================
Experiment: BASIC_ep7_adaptive_noise_alpha0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9887, Val Acc: 0.8876
  Time: 6.66s

[133/510]

============================================================
Experiment: BASIC_ep7_adaptive_noise_alpha0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9896, Val Acc: 0.8896
  Time: 6.62s

[134/510]

============================================================
Experiment: BASIC_ep7_adaptive_noise_alpha0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9892, Val Acc: 0.8844
  Time: 6.66s

[135/510]

============================================================
Experiment: BASIC_ep7_adaptive_noise_alpha0.7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9886, Val Acc: 0.8844
  Time: 6.61s

[136/510]

============================================================
Experiment: BASIC_ep7_adaptive_noise_alpha1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9875, Val Acc: 0.8828
  Time: 6.66s

[137/510]

============================================================
Experiment: BASIC_ep10_none_
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9954, Val Acc: 0.8914
  Time: 9.14s

[138/510]

============================================================
Experiment: BASIC_ep10_output_perturbation_scale0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9955, Val Acc: 0.8894
  Time: 9.20s

[139/510]

============================================================
Experiment: BASIC_ep10_output_perturbation_scale0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9941, Val Acc: 0.8932
  Time: 9.07s

[140/510]

============================================================
Experiment: BASIC_ep10_output_perturbation_scale0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9946, Val Acc: 0.8888
  Time: 9.15s

[141/510]

============================================================
Experiment: BASIC_ep10_output_perturbation_scale0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9963, Val Acc: 0.8916
  Time: 9.20s

[142/510]

============================================================
Experiment: BASIC_ep10_output_perturbation_scale0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9927, Val Acc: 0.8870
  Time: 11.45s

[143/510]

============================================================
Experiment: BASIC_ep10_input_perturbation_sigma0.01
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9952, Val Acc: 0.8902
  Time: 10.36s

[144/510]

============================================================
Experiment: BASIC_ep10_input_perturbation_sigma0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9932, Val Acc: 0.8826
  Time: 19.62s

[145/510]

============================================================
Experiment: BASIC_ep10_input_perturbation_sigma0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9815, Val Acc: 0.8740
  Time: 9.88s

[146/510]

============================================================
Experiment: BASIC_ep10_input_perturbation_sigma0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8618, Val Acc: 0.7744
  Time: 9.20s

[147/510]

============================================================
Experiment: BASIC_ep10_input_perturbation_sigma0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.3423, Val Acc: 0.3336
  Time: 9.15s

[148/510]

============================================================
Experiment: BASIC_ep10_input_perturbation_sigma1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.1422, Val Acc: 0.1454
  Time: 9.20s

[149/510]

============================================================
Experiment: BASIC_ep10_test_time_augmentation_num_augmentations1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9560, Val Acc: 0.8604
  Time: 9.30s

[150/510]

============================================================
Experiment: BASIC_ep10_test_time_augmentation_num_augmentations3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9837, Val Acc: 0.8718
  Time: 9.74s

[151/510]

============================================================
Experiment: BASIC_ep10_test_time_augmentation_num_augmentations5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9902, Val Acc: 0.8860
  Time: 10.38s

[152/510]

============================================================
Experiment: BASIC_ep10_test_time_augmentation_num_augmentations7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9869, Val Acc: 0.8770
  Time: 10.89s

[153/510]

============================================================
Experiment: BASIC_ep10_test_time_augmentation_num_augmentations10
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9913, Val Acc: 0.8808
  Time: 11.82s

[154/510]

============================================================
Experiment: BASIC_ep10_temperature_scaled_temp1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9950, Val Acc: 0.8886
  Time: 9.20s

[155/510]

============================================================
Experiment: BASIC_ep10_temperature_scaled_temp1.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9947, Val Acc: 0.8908
  Time: 9.14s

[156/510]

============================================================
Experiment: BASIC_ep10_temperature_scaled_temp2.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9951, Val Acc: 0.8912
  Time: 9.21s

[157/510]

============================================================
Experiment: BASIC_ep10_temperature_scaled_temp3.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9958, Val Acc: 0.8914
  Time: 9.12s

[158/510]

============================================================
Experiment: BASIC_ep10_temperature_scaled_temp5.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9929, Val Acc: 0.8902
  Time: 9.15s

[159/510]

============================================================
Experiment: BASIC_ep10_temperature_scaled_temp10.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9937, Val Acc: 0.8876
  Time: 9.18s

[160/510]

============================================================
Experiment: BASIC_ep10_response_limited_topk_top_k1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9946, Val Acc: 0.8860
  Time: 9.44s

[161/510]

============================================================
Experiment: BASIC_ep10_response_limited_topk_top_k2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9956, Val Acc: 0.8892
  Time: 9.18s

[162/510]

============================================================
Experiment: BASIC_ep10_response_limited_topk_top_k3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9946, Val Acc: 0.8904
  Time: 9.16s

[163/510]

============================================================
Experiment: BASIC_ep10_response_limited_topk_top_k4
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9951, Val Acc: 0.8924
  Time: 9.09s

[164/510]

============================================================
Experiment: BASIC_ep10_response_limited_topk_top_k5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9941, Val Acc: 0.8906
  Time: 9.16s

[165/510]

============================================================
Experiment: BASIC_ep10_response_limited_hard_hard_labelTrue
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9958, Val Acc: 0.8910
  Time: 9.13s

[166/510]

============================================================
Experiment: BASIC_ep10_adaptive_noise_alpha0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9944, Val Acc: 0.8916
  Time: 9.29s

[167/510]

============================================================
Experiment: BASIC_ep10_adaptive_noise_alpha0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9947, Val Acc: 0.8914
  Time: 9.16s

[168/510]

============================================================
Experiment: BASIC_ep10_adaptive_noise_alpha0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9940, Val Acc: 0.8868
  Time: 9.08s

[169/510]

============================================================
Experiment: BASIC_ep10_adaptive_noise_alpha0.7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9920, Val Acc: 0.8900
  Time: 9.14s

[170/510]

============================================================
Experiment: BASIC_ep10_adaptive_noise_alpha1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with BASIC for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9923, Val Acc: 0.8876
  Time: 9.09s

[171/510]

============================================================
Experiment: PGD_ep1_none_
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6348, Val Acc: 0.6074
  Time: 10.16s

[172/510]

============================================================
Experiment: PGD_ep1_output_perturbation_scale0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6811, Val Acc: 0.6468
  Time: 5.83s

[173/510]

============================================================
Experiment: PGD_ep1_output_perturbation_scale0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6865, Val Acc: 0.6520
  Time: 5.83s

[174/510]

============================================================
Experiment: PGD_ep1_output_perturbation_scale0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6130, Val Acc: 0.5910
  Time: 5.84s

[175/510]

============================================================
Experiment: PGD_ep1_output_perturbation_scale0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6009, Val Acc: 0.5766
  Time: 5.83s

[176/510]

============================================================
Experiment: PGD_ep1_output_perturbation_scale0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6403, Val Acc: 0.6160
  Time: 5.83s

[177/510]

============================================================
Experiment: PGD_ep1_input_perturbation_sigma0.01
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6399, Val Acc: 0.6114
  Time: 5.84s

[178/510]

============================================================
Experiment: PGD_ep1_input_perturbation_sigma0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6446, Val Acc: 0.6154
  Time: 5.92s

[179/510]

============================================================
Experiment: PGD_ep1_input_perturbation_sigma0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6615, Val Acc: 0.6314
  Time: 5.84s

[180/510]

============================================================
Experiment: PGD_ep1_input_perturbation_sigma0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5783, Val Acc: 0.5636
  Time: 5.83s

[181/510]

============================================================
Experiment: PGD_ep1_input_perturbation_sigma0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.3980, Val Acc: 0.3896
  Time: 10.52s

[182/510]

============================================================
Experiment: PGD_ep1_input_perturbation_sigma1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.2015, Val Acc: 0.1986
  Time: 5.83s

[183/510]

============================================================
Experiment: PGD_ep1_test_time_augmentation_num_augmentations1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5566, Val Acc: 0.5644
  Time: 6.10s

[184/510]

============================================================
Experiment: PGD_ep1_test_time_augmentation_num_augmentations3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5801, Val Acc: 0.5628
  Time: 6.42s

[185/510]

============================================================
Experiment: PGD_ep1_test_time_augmentation_num_augmentations5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6024, Val Acc: 0.5742
  Time: 7.08s

[186/510]

============================================================
Experiment: PGD_ep1_test_time_augmentation_num_augmentations7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5440, Val Acc: 0.5294
  Time: 7.58s

[187/510]

============================================================
Experiment: PGD_ep1_test_time_augmentation_num_augmentations10
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5877, Val Acc: 0.5562
  Time: 8.46s

[188/510]

============================================================
Experiment: PGD_ep1_temperature_scaled_temp1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6888, Val Acc: 0.6540
  Time: 5.83s

[189/510]

============================================================
Experiment: PGD_ep1_temperature_scaled_temp1.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6621, Val Acc: 0.6350
  Time: 5.83s

[190/510]

============================================================
Experiment: PGD_ep1_temperature_scaled_temp2.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6788, Val Acc: 0.6454
  Time: 5.81s

[191/510]

============================================================
Experiment: PGD_ep1_temperature_scaled_temp3.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6367, Val Acc: 0.6094
  Time: 5.83s

[192/510]

============================================================
Experiment: PGD_ep1_temperature_scaled_temp5.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6821, Val Acc: 0.6490
  Time: 5.91s

[193/510]

============================================================
Experiment: PGD_ep1_temperature_scaled_temp10.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6849, Val Acc: 0.6500
  Time: 5.83s

[194/510]

============================================================
Experiment: PGD_ep1_response_limited_topk_top_k1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6881, Val Acc: 0.6546
  Time: 6.39s

[195/510]

============================================================
Experiment: PGD_ep1_response_limited_topk_top_k2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6322, Val Acc: 0.6058
  Time: 6.00s

[196/510]

============================================================
Experiment: PGD_ep1_response_limited_topk_top_k3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6851, Val Acc: 0.6510
  Time: 5.84s

[197/510]

============================================================
Experiment: PGD_ep1_response_limited_topk_top_k4
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6515, Val Acc: 0.6244
  Time: 5.83s

[198/510]

============================================================
Experiment: PGD_ep1_response_limited_topk_top_k5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6677, Val Acc: 0.6382
  Time: 5.82s

[199/510]

============================================================
Experiment: PGD_ep1_response_limited_hard_hard_labelTrue
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6854, Val Acc: 0.6520
  Time: 5.98s

[200/510]

============================================================
Experiment: PGD_ep1_adaptive_noise_alpha0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6580, Val Acc: 0.6310
  Time: 6.04s

[201/510]

============================================================
Experiment: PGD_ep1_adaptive_noise_alpha0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6848, Val Acc: 0.6502
  Time: 5.84s

[202/510]

============================================================
Experiment: PGD_ep1_adaptive_noise_alpha0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6616, Val Acc: 0.6342
  Time: 5.83s

[203/510]

============================================================
Experiment: PGD_ep1_adaptive_noise_alpha0.7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6284, Val Acc: 0.6080
  Time: 5.83s

[204/510]

============================================================
Experiment: PGD_ep1_adaptive_noise_alpha1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6587, Val Acc: 0.6268
  Time: 5.83s

[205/510]

============================================================
Experiment: PGD_ep3_none_
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6658, Val Acc: 0.6364
  Time: 16.20s

[206/510]

============================================================
Experiment: PGD_ep3_output_perturbation_scale0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.7077, Val Acc: 0.6670
  Time: 16.14s

[207/510]

============================================================
Experiment: PGD_ep3_output_perturbation_scale0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6905, Val Acc: 0.6568
  Time: 16.15s

[208/510]

============================================================
Experiment: PGD_ep3_output_perturbation_scale0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6915, Val Acc: 0.6574
  Time: 16.15s

[209/510]

============================================================
Experiment: PGD_ep3_output_perturbation_scale0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6674, Val Acc: 0.6382
  Time: 16.23s

[210/510]

============================================================
Experiment: PGD_ep3_output_perturbation_scale0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6718, Val Acc: 0.6308
  Time: 16.15s

[211/510]

============================================================
Experiment: PGD_ep3_input_perturbation_sigma0.01
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.7053, Val Acc: 0.6666
  Time: 16.14s

[212/510]

============================================================
Experiment: PGD_ep3_input_perturbation_sigma0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6670, Val Acc: 0.6374
  Time: 16.15s

[213/510]

============================================================
Experiment: PGD_ep3_input_perturbation_sigma0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6977, Val Acc: 0.6604
  Time: 16.15s

[214/510]

============================================================
Experiment: PGD_ep3_input_perturbation_sigma0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6572, Val Acc: 0.6278
  Time: 16.19s

[215/510]

============================================================
Experiment: PGD_ep3_input_perturbation_sigma0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.3909, Val Acc: 0.3872
  Time: 16.15s

[216/510]

============================================================
Experiment: PGD_ep3_input_perturbation_sigma1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.2158, Val Acc: 0.2172
  Time: 16.14s

[217/510]

============================================================
Experiment: PGD_ep3_test_time_augmentation_num_augmentations1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5804, Val Acc: 0.5590
  Time: 16.16s

[218/510]

============================================================
Experiment: PGD_ep3_test_time_augmentation_num_augmentations3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5872, Val Acc: 0.5522
  Time: 16.77s

[219/510]

============================================================
Experiment: PGD_ep3_test_time_augmentation_num_augmentations5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5808, Val Acc: 0.5658
  Time: 17.30s

[220/510]

============================================================
Experiment: PGD_ep3_test_time_augmentation_num_augmentations7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5810, Val Acc: 0.5664
  Time: 17.87s

[221/510]

============================================================
Experiment: PGD_ep3_test_time_augmentation_num_augmentations10
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5936, Val Acc: 0.5600
  Time: 18.76s

[222/510]

============================================================
Experiment: PGD_ep3_temperature_scaled_temp1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.7019, Val Acc: 0.6664
  Time: 16.19s

[223/510]

============================================================
Experiment: PGD_ep3_temperature_scaled_temp1.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6828, Val Acc: 0.6526
  Time: 16.14s

[224/510]

============================================================
Experiment: PGD_ep3_temperature_scaled_temp2.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6788, Val Acc: 0.6474
  Time: 16.13s

[225/510]

============================================================
Experiment: PGD_ep3_temperature_scaled_temp3.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6913, Val Acc: 0.6596
  Time: 16.14s

[226/510]

============================================================
Experiment: PGD_ep3_temperature_scaled_temp5.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.7006, Val Acc: 0.6642
  Time: 16.20s

[227/510]

============================================================
Experiment: PGD_ep3_temperature_scaled_temp10.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6906, Val Acc: 0.6578
  Time: 16.14s

[228/510]

============================================================
Experiment: PGD_ep3_response_limited_topk_top_k1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6906, Val Acc: 0.6582
  Time: 16.14s

[229/510]

============================================================
Experiment: PGD_ep3_response_limited_topk_top_k2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6804, Val Acc: 0.6496
  Time: 16.14s

[230/510]

============================================================
Experiment: PGD_ep3_response_limited_topk_top_k3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.7016, Val Acc: 0.6660
  Time: 16.19s

[231/510]

============================================================
Experiment: PGD_ep3_response_limited_topk_top_k4
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6615, Val Acc: 0.6340
  Time: 16.13s

[232/510]

============================================================
Experiment: PGD_ep3_response_limited_topk_top_k5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.7066, Val Acc: 0.6666
  Time: 16.16s

[233/510]

============================================================
Experiment: PGD_ep3_response_limited_hard_hard_labelTrue
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.7070, Val Acc: 0.6668
  Time: 16.14s

[234/510]

============================================================
Experiment: PGD_ep3_adaptive_noise_alpha0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6842, Val Acc: 0.6508
  Time: 16.19s

[235/510]

============================================================
Experiment: PGD_ep3_adaptive_noise_alpha0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6880, Val Acc: 0.6536
  Time: 16.13s

[236/510]

============================================================
Experiment: PGD_ep3_adaptive_noise_alpha0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6966, Val Acc: 0.6636
  Time: 16.15s

[237/510]

============================================================
Experiment: PGD_ep3_adaptive_noise_alpha0.7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6472, Val Acc: 0.6228
  Time: 16.15s

[238/510]

============================================================
Experiment: PGD_ep3_adaptive_noise_alpha1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6767, Val Acc: 0.6436
  Time: 16.19s

[239/510]

============================================================
Experiment: PGD_ep5_none_
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6520, Val Acc: 0.6214
  Time: 26.45s

[240/510]

============================================================
Experiment: PGD_ep5_output_perturbation_scale0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6785, Val Acc: 0.6334
  Time: 26.45s

[241/510]

============================================================
Experiment: PGD_ep5_output_perturbation_scale0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6527, Val Acc: 0.6224
  Time: 26.51s

[242/510]

============================================================
Experiment: PGD_ep5_output_perturbation_scale0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6418, Val Acc: 0.6100
  Time: 26.46s

[243/510]

============================================================
Experiment: PGD_ep5_output_perturbation_scale0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6703, Val Acc: 0.6238
  Time: 26.46s

[244/510]

============================================================
Experiment: PGD_ep5_output_perturbation_scale0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6593, Val Acc: 0.6214
  Time: 26.49s

[245/510]

============================================================
Experiment: PGD_ep5_input_perturbation_sigma0.01
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6659, Val Acc: 0.6338
  Time: 26.45s

[246/510]

============================================================
Experiment: PGD_ep5_input_perturbation_sigma0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6771, Val Acc: 0.6338
  Time: 26.46s

[247/510]

============================================================
Experiment: PGD_ep5_input_perturbation_sigma0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6667, Val Acc: 0.6292
  Time: 26.51s

[248/510]

============================================================
Experiment: PGD_ep5_input_perturbation_sigma0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6126, Val Acc: 0.5892
  Time: 26.46s

[249/510]

============================================================
Experiment: PGD_ep5_input_perturbation_sigma0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.4079, Val Acc: 0.4058
  Time: 26.47s

[250/510]

============================================================
Experiment: PGD_ep5_input_perturbation_sigma1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.2028, Val Acc: 0.2102
  Time: 26.54s

[251/510]

============================================================
Experiment: PGD_ep5_test_time_augmentation_num_augmentations1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5525, Val Acc: 0.5016
  Time: 26.48s

[252/510]

============================================================
Experiment: PGD_ep5_test_time_augmentation_num_augmentations3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5659, Val Acc: 0.5638
  Time: 27.13s

[253/510]

============================================================
Experiment: PGD_ep5_test_time_augmentation_num_augmentations5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5768, Val Acc: 0.5570
  Time: 27.64s

[254/510]

============================================================
Experiment: PGD_ep5_test_time_augmentation_num_augmentations7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5798, Val Acc: 0.5516
  Time: 28.22s

[255/510]

============================================================
Experiment: PGD_ep5_test_time_augmentation_num_augmentations10
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5941, Val Acc: 0.5700
  Time: 29.14s

[256/510]

============================================================
Experiment: PGD_ep5_temperature_scaled_temp1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6424, Val Acc: 0.6152
  Time: 26.48s

[257/510]

============================================================
Experiment: PGD_ep5_temperature_scaled_temp1.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6584, Val Acc: 0.6274
  Time: 26.46s

[258/510]

============================================================
Experiment: PGD_ep5_temperature_scaled_temp2.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6563, Val Acc: 0.6248
  Time: 26.52s

[259/510]

============================================================
Experiment: PGD_ep5_temperature_scaled_temp3.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6506, Val Acc: 0.6200
  Time: 26.46s

[260/510]

============================================================
Experiment: PGD_ep5_temperature_scaled_temp5.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6705, Val Acc: 0.6346
  Time: 26.46s

[261/510]

============================================================
Experiment: PGD_ep5_temperature_scaled_temp10.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6755, Val Acc: 0.6346
  Time: 26.53s

[262/510]

============================================================
Experiment: PGD_ep5_response_limited_topk_top_k1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6472, Val Acc: 0.6174
  Time: 26.47s

[263/510]

============================================================
Experiment: PGD_ep5_response_limited_topk_top_k2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6714, Val Acc: 0.6342
  Time: 26.47s

[264/510]

============================================================
Experiment: PGD_ep5_response_limited_topk_top_k3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6764, Val Acc: 0.6354
  Time: 26.51s

[265/510]

============================================================
Experiment: PGD_ep5_response_limited_topk_top_k4
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6667, Val Acc: 0.6340
  Time: 26.47s

[266/510]

============================================================
Experiment: PGD_ep5_response_limited_topk_top_k5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6471, Val Acc: 0.6182
  Time: 26.46s

[267/510]

============================================================
Experiment: PGD_ep5_response_limited_hard_hard_labelTrue
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6754, Val Acc: 0.6354
  Time: 26.51s

[268/510]

============================================================
Experiment: PGD_ep5_adaptive_noise_alpha0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6701, Val Acc: 0.6342
  Time: 26.47s

[269/510]

============================================================
Experiment: PGD_ep5_adaptive_noise_alpha0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6636, Val Acc: 0.6328
  Time: 26.55s

[270/510]

============================================================
Experiment: PGD_ep5_adaptive_noise_alpha0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6785, Val Acc: 0.6386
  Time: 26.47s

[271/510]

============================================================
Experiment: PGD_ep5_adaptive_noise_alpha0.7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6721, Val Acc: 0.6302
  Time: 26.47s

[272/510]

============================================================
Experiment: PGD_ep5_adaptive_noise_alpha1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6482, Val Acc: 0.6126
  Time: 26.51s

[273/510]

============================================================
Experiment: PGD_ep7_none_
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6140, Val Acc: 0.5812
  Time: 36.77s

[274/510]

============================================================
Experiment: PGD_ep7_output_perturbation_scale0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6331, Val Acc: 0.5892
  Time: 36.86s

[275/510]

============================================================
Experiment: PGD_ep7_output_perturbation_scale0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6371, Val Acc: 0.5978
  Time: 36.78s

[276/510]

============================================================
Experiment: PGD_ep7_output_perturbation_scale0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6109, Val Acc: 0.5778
  Time: 36.77s

[277/510]

============================================================
Experiment: PGD_ep7_output_perturbation_scale0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6276, Val Acc: 0.5836
  Time: 36.84s

[278/510]

============================================================
Experiment: PGD_ep7_output_perturbation_scale0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6105, Val Acc: 0.5708
  Time: 50.90s

[279/510]

============================================================
Experiment: PGD_ep7_input_perturbation_sigma0.01
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6336, Val Acc: 0.5932
  Time: 37.46s

[280/510]

============================================================
Experiment: PGD_ep7_input_perturbation_sigma0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6202, Val Acc: 0.5830
  Time: 36.77s

[281/510]

============================================================
Experiment: PGD_ep7_input_perturbation_sigma0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6129, Val Acc: 0.5784
  Time: 36.83s

[282/510]

============================================================
Experiment: PGD_ep7_input_perturbation_sigma0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5988, Val Acc: 0.5632
  Time: 36.77s

[283/510]

============================================================
Experiment: PGD_ep7_input_perturbation_sigma0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.3937, Val Acc: 0.3932
  Time: 36.83s

[284/510]

============================================================
Experiment: PGD_ep7_input_perturbation_sigma1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.1925, Val Acc: 0.2010
  Time: 36.78s

[285/510]

============================================================
Experiment: PGD_ep7_test_time_augmentation_num_augmentations1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5067, Val Acc: 0.5056
  Time: 38.11s

[286/510]

============================================================
Experiment: PGD_ep7_test_time_augmentation_num_augmentations3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5395, Val Acc: 0.5130
  Time: 37.37s

[287/510]

============================================================
Experiment: PGD_ep7_test_time_augmentation_num_augmentations5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5485, Val Acc: 0.5282
  Time: 37.96s

[288/510]

============================================================
Experiment: PGD_ep7_test_time_augmentation_num_augmentations7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5526, Val Acc: 0.5302
  Time: 38.60s

[289/510]

============================================================
Experiment: PGD_ep7_test_time_augmentation_num_augmentations10
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5496, Val Acc: 0.5308
  Time: 39.40s

[290/510]

============================================================
Experiment: PGD_ep7_temperature_scaled_temp1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6193, Val Acc: 0.5812
  Time: 36.84s

[291/510]

============================================================
Experiment: PGD_ep7_temperature_scaled_temp1.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6166, Val Acc: 0.5792
  Time: 36.78s

[292/510]

============================================================
Experiment: PGD_ep7_temperature_scaled_temp2.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6351, Val Acc: 0.5982
  Time: 36.82s

[293/510]

============================================================
Experiment: PGD_ep7_temperature_scaled_temp3.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6310, Val Acc: 0.5850
  Time: 36.78s

[294/510]

============================================================
Experiment: PGD_ep7_temperature_scaled_temp5.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6324, Val Acc: 0.5886
  Time: 36.84s

[295/510]

============================================================
Experiment: PGD_ep7_temperature_scaled_temp10.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6139, Val Acc: 0.5792
  Time: 36.79s

[296/510]

============================================================
Experiment: PGD_ep7_response_limited_topk_top_k1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6359, Val Acc: 0.5932
  Time: 37.19s

[297/510]

============================================================
Experiment: PGD_ep7_response_limited_topk_top_k2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6329, Val Acc: 0.5900
  Time: 54.81s

[298/510]

============================================================
Experiment: PGD_ep7_response_limited_topk_top_k3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6172, Val Acc: 0.5820
  Time: 36.94s

[299/510]

============================================================
Experiment: PGD_ep7_response_limited_topk_top_k4
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6187, Val Acc: 0.5802
  Time: 36.83s

[300/510]

============================================================
Experiment: PGD_ep7_response_limited_topk_top_k5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6370, Val Acc: 0.5976
  Time: 36.78s

[301/510]

============================================================
Experiment: PGD_ep7_response_limited_hard_hard_labelTrue
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6240, Val Acc: 0.5850
  Time: 37.42s

[302/510]

============================================================
Experiment: PGD_ep7_adaptive_noise_alpha0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6315, Val Acc: 0.5890
  Time: 38.26s

[303/510]

============================================================
Experiment: PGD_ep7_adaptive_noise_alpha0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6341, Val Acc: 0.5940
  Time: 36.85s

[304/510]

============================================================
Experiment: PGD_ep7_adaptive_noise_alpha0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6153, Val Acc: 0.5810
  Time: 37.00s

[305/510]

============================================================
Experiment: PGD_ep7_adaptive_noise_alpha0.7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6085, Val Acc: 0.5794
  Time: 43.97s

[306/510]

============================================================
Experiment: PGD_ep7_adaptive_noise_alpha1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.6229, Val Acc: 0.5788
  Time: 36.77s

[307/510]

============================================================
Experiment: PGD_ep10_none_
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5379, Val Acc: 0.5034
  Time: 52.29s

[308/510]

============================================================
Experiment: PGD_ep10_output_perturbation_scale0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5529, Val Acc: 0.5194
  Time: 52.24s

[309/510]

============================================================
Experiment: PGD_ep10_output_perturbation_scale0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5213, Val Acc: 0.4928
  Time: 52.29s

[310/510]

============================================================
Experiment: PGD_ep10_output_perturbation_scale0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5393, Val Acc: 0.5084
  Time: 52.33s

[311/510]

============================================================
Experiment: PGD_ep10_output_perturbation_scale0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5411, Val Acc: 0.5062
  Time: 52.24s

[312/510]

============================================================
Experiment: PGD_ep10_output_perturbation_scale0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5212, Val Acc: 0.4906
  Time: 52.28s

[313/510]

============================================================
Experiment: PGD_ep10_input_perturbation_sigma0.01
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5463, Val Acc: 0.5108
  Time: 52.26s

[314/510]

============================================================
Experiment: PGD_ep10_input_perturbation_sigma0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5214, Val Acc: 0.4928
  Time: 52.30s

[315/510]

============================================================
Experiment: PGD_ep10_input_perturbation_sigma0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5139, Val Acc: 0.4868
  Time: 52.32s

[316/510]

============================================================
Experiment: PGD_ep10_input_perturbation_sigma0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5164, Val Acc: 0.4870
  Time: 52.25s

[317/510]

============================================================
Experiment: PGD_ep10_input_perturbation_sigma0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.3387, Val Acc: 0.3332
  Time: 52.30s

[318/510]

============================================================
Experiment: PGD_ep10_input_perturbation_sigma1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.1767, Val Acc: 0.1814
  Time: 52.25s

[319/510]

============================================================
Experiment: PGD_ep10_test_time_augmentation_num_augmentations1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.4204, Val Acc: 0.4148
  Time: 59.05s

[320/510]

============================================================
Experiment: PGD_ep10_test_time_augmentation_num_augmentations3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.4858, Val Acc: 0.4686
  Time: 53.06s

[321/510]

============================================================
Experiment: PGD_ep10_test_time_augmentation_num_augmentations5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.4626, Val Acc: 0.4522
  Time: 53.42s

[322/510]

============================================================
Experiment: PGD_ep10_test_time_augmentation_num_augmentations7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.4981, Val Acc: 0.4756
  Time: 54.04s

[323/510]

============================================================
Experiment: PGD_ep10_test_time_augmentation_num_augmentations10
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.4668, Val Acc: 0.4582
  Time: 54.85s

[324/510]

============================================================
Experiment: PGD_ep10_temperature_scaled_temp1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5561, Val Acc: 0.5212
  Time: 52.30s

[325/510]

============================================================
Experiment: PGD_ep10_temperature_scaled_temp1.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5226, Val Acc: 0.4948
  Time: 59.24s

[326/510]

============================================================
Experiment: PGD_ep10_temperature_scaled_temp2.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5201, Val Acc: 0.4904
  Time: 102.66s

[327/510]

============================================================
Experiment: PGD_ep10_temperature_scaled_temp3.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5438, Val Acc: 0.5106
  Time: 54.49s

[328/510]

============================================================
Experiment: PGD_ep10_temperature_scaled_temp5.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5220, Val Acc: 0.4934
  Time: 52.87s

[329/510]

============================================================
Experiment: PGD_ep10_temperature_scaled_temp10.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5204, Val Acc: 0.4896
  Time: 52.23s

[330/510]

============================================================
Experiment: PGD_ep10_response_limited_topk_top_k1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5405, Val Acc: 0.5076
  Time: 58.83s

[331/510]

============================================================
Experiment: PGD_ep10_response_limited_topk_top_k2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5445, Val Acc: 0.5112
  Time: 52.29s

[332/510]

============================================================
Experiment: PGD_ep10_response_limited_topk_top_k3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5175, Val Acc: 0.4846
  Time: 52.31s

[333/510]

============================================================
Experiment: PGD_ep10_response_limited_topk_top_k4
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5353, Val Acc: 0.5040
  Time: 52.30s

[334/510]

============================================================
Experiment: PGD_ep10_response_limited_topk_top_k5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5451, Val Acc: 0.5104
  Time: 52.25s

[335/510]

============================================================
Experiment: PGD_ep10_response_limited_hard_hard_labelTrue
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5231, Val Acc: 0.4932
  Time: 52.63s

[336/510]

============================================================
Experiment: PGD_ep10_adaptive_noise_alpha0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5364, Val Acc: 0.5034
  Time: 52.48s

[337/510]

============================================================
Experiment: PGD_ep10_adaptive_noise_alpha0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5569, Val Acc: 0.5228
  Time: 52.30s

[338/510]

============================================================
Experiment: PGD_ep10_adaptive_noise_alpha0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5302, Val Acc: 0.4996
  Time: 52.29s

[339/510]

============================================================
Experiment: PGD_ep10_adaptive_noise_alpha0.7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5183, Val Acc: 0.4868
  Time: 52.25s

[340/510]

============================================================
Experiment: PGD_ep10_adaptive_noise_alpha1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with PGD for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.5119, Val Acc: 0.4794
  Time: 52.30s

[341/510]

============================================================
Experiment: FGSM_ep1_none_
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9109, Val Acc: 0.8292
  Time: 2.09s

[342/510]

============================================================
Experiment: FGSM_ep1_output_perturbation_scale0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9092, Val Acc: 0.8302
  Time: 2.15s

[343/510]

============================================================
Experiment: FGSM_ep1_output_perturbation_scale0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9144, Val Acc: 0.8348
  Time: 2.09s

[344/510]

============================================================
Experiment: FGSM_ep1_output_perturbation_scale0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9126, Val Acc: 0.8336
  Time: 2.09s

[345/510]

============================================================
Experiment: FGSM_ep1_output_perturbation_scale0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9045, Val Acc: 0.8288
  Time: 2.14s

[346/510]

============================================================
Experiment: FGSM_ep1_output_perturbation_scale0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8863, Val Acc: 0.8018
  Time: 2.10s

[347/510]

============================================================
Experiment: FGSM_ep1_input_perturbation_sigma0.01
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9114, Val Acc: 0.8288
  Time: 2.08s

[348/510]

============================================================
Experiment: FGSM_ep1_input_perturbation_sigma0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9121, Val Acc: 0.8320
  Time: 2.11s

[349/510]

============================================================
Experiment: FGSM_ep1_input_perturbation_sigma0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8917, Val Acc: 0.8138
  Time: 2.08s

[350/510]

============================================================
Experiment: FGSM_ep1_input_perturbation_sigma0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.7598, Val Acc: 0.7094
  Time: 2.10s

[351/510]

============================================================
Experiment: FGSM_ep1_input_perturbation_sigma0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.3066, Val Acc: 0.2976
  Time: 2.09s

[352/510]

============================================================
Experiment: FGSM_ep1_input_perturbation_sigma1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.1653, Val Acc: 0.1640
  Time: 2.16s

[353/510]

============================================================
Experiment: FGSM_ep1_test_time_augmentation_num_augmentations1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8311, Val Acc: 0.7670
  Time: 2.87s

[354/510]

============================================================
Experiment: FGSM_ep1_test_time_augmentation_num_augmentations3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8649, Val Acc: 0.7942
  Time: 2.69s

[355/510]

============================================================
Experiment: FGSM_ep1_test_time_augmentation_num_augmentations5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8607, Val Acc: 0.7894
  Time: 3.25s

[356/510]

============================================================
Experiment: FGSM_ep1_test_time_augmentation_num_augmentations7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8746, Val Acc: 0.8084
  Time: 3.84s

[357/510]

============================================================
Experiment: FGSM_ep1_test_time_augmentation_num_augmentations10
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8782, Val Acc: 0.8040
  Time: 4.71s

[358/510]

============================================================
Experiment: FGSM_ep1_temperature_scaled_temp1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9128, Val Acc: 0.8300
  Time: 2.09s

[359/510]

============================================================
Experiment: FGSM_ep1_temperature_scaled_temp1.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9141, Val Acc: 0.8320
  Time: 2.15s

[360/510]

============================================================
Experiment: FGSM_ep1_temperature_scaled_temp2.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9133, Val Acc: 0.8304
  Time: 2.09s

[361/510]

============================================================
Experiment: FGSM_ep1_temperature_scaled_temp3.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9155, Val Acc: 0.8346
  Time: 2.09s

[362/510]

============================================================
Experiment: FGSM_ep1_temperature_scaled_temp5.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9073, Val Acc: 0.8262
  Time: 2.08s

[363/510]

============================================================
Experiment: FGSM_ep1_temperature_scaled_temp10.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9166, Val Acc: 0.8350
  Time: 2.08s

[364/510]

============================================================
Experiment: FGSM_ep1_response_limited_topk_top_k1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9165, Val Acc: 0.8354
  Time: 2.09s

[365/510]

============================================================
Experiment: FGSM_ep1_response_limited_topk_top_k2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9127, Val Acc: 0.8302
  Time: 2.08s

[366/510]

============================================================
Experiment: FGSM_ep1_response_limited_topk_top_k3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9163, Val Acc: 0.8356
  Time: 2.16s

[367/510]

============================================================
Experiment: FGSM_ep1_response_limited_topk_top_k4
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9085, Val Acc: 0.8272
  Time: 2.12s

[368/510]

============================================================
Experiment: FGSM_ep1_response_limited_topk_top_k5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9089, Val Acc: 0.8272
  Time: 2.09s

[369/510]

============================================================
Experiment: FGSM_ep1_response_limited_hard_hard_labelTrue
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9167, Val Acc: 0.8346
  Time: 2.09s

[370/510]

============================================================
Experiment: FGSM_ep1_adaptive_noise_alpha0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9159, Val Acc: 0.8354
  Time: 2.09s

[371/510]

============================================================
Experiment: FGSM_ep1_adaptive_noise_alpha0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9119, Val Acc: 0.8314
  Time: 2.10s

[372/510]

============================================================
Experiment: FGSM_ep1_adaptive_noise_alpha0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9123, Val Acc: 0.8352
  Time: 2.09s

[373/510]

============================================================
Experiment: FGSM_ep1_adaptive_noise_alpha0.7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9042, Val Acc: 0.8216
  Time: 2.17s

[374/510]

============================================================
Experiment: FGSM_ep1_adaptive_noise_alpha1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 1 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8907, Val Acc: 0.8082
  Time: 2.09s

[375/510]

============================================================
Experiment: FGSM_ep3_none_
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9246, Val Acc: 0.8458
  Time: 4.91s

[376/510]

============================================================
Experiment: FGSM_ep3_output_perturbation_scale0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9184, Val Acc: 0.8408
  Time: 4.92s

[377/510]

============================================================
Experiment: FGSM_ep3_output_perturbation_scale0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9250, Val Acc: 0.8440
  Time: 4.92s

[378/510]

============================================================
Experiment: FGSM_ep3_output_perturbation_scale0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9257, Val Acc: 0.8446
  Time: 4.98s

[379/510]

============================================================
Experiment: FGSM_ep3_output_perturbation_scale0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9232, Val Acc: 0.8434
  Time: 4.92s

[380/510]

============================================================
Experiment: FGSM_ep3_output_perturbation_scale0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8942, Val Acc: 0.8126
  Time: 4.92s

[381/510]

============================================================
Experiment: FGSM_ep3_input_perturbation_sigma0.01
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9204, Val Acc: 0.8434
  Time: 4.94s

[382/510]

============================================================
Experiment: FGSM_ep3_input_perturbation_sigma0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9145, Val Acc: 0.8358
  Time: 4.98s

[383/510]

============================================================
Experiment: FGSM_ep3_input_perturbation_sigma0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9026, Val Acc: 0.8252
  Time: 4.93s

[384/510]

============================================================
Experiment: FGSM_ep3_input_perturbation_sigma0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.7969, Val Acc: 0.7394
  Time: 4.92s

[385/510]

============================================================
Experiment: FGSM_ep3_input_perturbation_sigma0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.3134, Val Acc: 0.3076
  Time: 4.92s

[386/510]

============================================================
Experiment: FGSM_ep3_input_perturbation_sigma1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.1363, Val Acc: 0.1372
  Time: 4.98s

[387/510]

============================================================
Experiment: FGSM_ep3_test_time_augmentation_num_augmentations1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8294, Val Acc: 0.7986
  Time: 4.93s

[388/510]

============================================================
Experiment: FGSM_ep3_test_time_augmentation_num_augmentations3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8667, Val Acc: 0.7968
  Time: 5.50s

[389/510]

============================================================
Experiment: FGSM_ep3_test_time_augmentation_num_augmentations5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8682, Val Acc: 0.8032
  Time: 6.08s

[390/510]

============================================================
Experiment: FGSM_ep3_test_time_augmentation_num_augmentations7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8740, Val Acc: 0.7980
  Time: 6.74s

[391/510]

============================================================
Experiment: FGSM_ep3_test_time_augmentation_num_augmentations10
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8772, Val Acc: 0.8016
  Time: 7.54s

[392/510]

============================================================
Experiment: FGSM_ep3_temperature_scaled_temp1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9216, Val Acc: 0.8442
  Time: 4.92s

[393/510]

============================================================
Experiment: FGSM_ep3_temperature_scaled_temp1.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9270, Val Acc: 0.8450
  Time: 4.91s

[394/510]

============================================================
Experiment: FGSM_ep3_temperature_scaled_temp2.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9285, Val Acc: 0.8476
  Time: 4.98s

[395/510]

============================================================
Experiment: FGSM_ep3_temperature_scaled_temp3.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9279, Val Acc: 0.8468
  Time: 4.91s

[396/510]

============================================================
Experiment: FGSM_ep3_temperature_scaled_temp5.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9251, Val Acc: 0.8458
  Time: 4.92s

[397/510]

============================================================
Experiment: FGSM_ep3_temperature_scaled_temp10.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9220, Val Acc: 0.8436
  Time: 4.92s

[398/510]

============================================================
Experiment: FGSM_ep3_response_limited_topk_top_k1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9294, Val Acc: 0.8472
  Time: 4.98s

[399/510]

============================================================
Experiment: FGSM_ep3_response_limited_topk_top_k2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9291, Val Acc: 0.8468
  Time: 4.93s

[400/510]

============================================================
Experiment: FGSM_ep3_response_limited_topk_top_k3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9267, Val Acc: 0.8450
  Time: 4.92s

[401/510]

============================================================
Experiment: FGSM_ep3_response_limited_topk_top_k4
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9247, Val Acc: 0.8454
  Time: 4.92s

[402/510]

============================================================
Experiment: FGSM_ep3_response_limited_topk_top_k5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9236, Val Acc: 0.8444
  Time: 4.98s

[403/510]

============================================================
Experiment: FGSM_ep3_response_limited_hard_hard_labelTrue
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9270, Val Acc: 0.8460
  Time: 4.92s

[404/510]

============================================================
Experiment: FGSM_ep3_adaptive_noise_alpha0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9202, Val Acc: 0.8428
  Time: 4.92s

[405/510]

============================================================
Experiment: FGSM_ep3_adaptive_noise_alpha0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9199, Val Acc: 0.8382
  Time: 4.91s

[406/510]

============================================================
Experiment: FGSM_ep3_adaptive_noise_alpha0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9224, Val Acc: 0.8408
  Time: 5.00s

[407/510]

============================================================
Experiment: FGSM_ep3_adaptive_noise_alpha0.7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9149, Val Acc: 0.8376
  Time: 4.92s

[408/510]

============================================================
Experiment: FGSM_ep3_adaptive_noise_alpha1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 3 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8980, Val Acc: 0.8228
  Time: 4.91s

[409/510]

============================================================
Experiment: FGSM_ep5_none_
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9329, Val Acc: 0.8478
  Time: 7.75s

[410/510]

============================================================
Experiment: FGSM_ep5_output_perturbation_scale0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9386, Val Acc: 0.8484
  Time: 7.80s

[411/510]

============================================================
Experiment: FGSM_ep5_output_perturbation_scale0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9389, Val Acc: 0.8500
  Time: 7.73s

[412/510]

============================================================
Experiment: FGSM_ep5_output_perturbation_scale0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9366, Val Acc: 0.8458
  Time: 7.76s

[413/510]

============================================================
Experiment: FGSM_ep5_output_perturbation_scale0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9305, Val Acc: 0.8412
  Time: 7.81s

[414/510]

============================================================
Experiment: FGSM_ep5_output_perturbation_scale0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9260, Val Acc: 0.8356
  Time: 7.74s

[415/510]

============================================================
Experiment: FGSM_ep5_input_perturbation_sigma0.01
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9361, Val Acc: 0.8486
  Time: 7.75s

[416/510]

============================================================
Experiment: FGSM_ep5_input_perturbation_sigma0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9315, Val Acc: 0.8442
  Time: 7.81s

[417/510]

============================================================
Experiment: FGSM_ep5_input_perturbation_sigma0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9195, Val Acc: 0.8334
  Time: 7.75s

[418/510]

============================================================
Experiment: FGSM_ep5_input_perturbation_sigma0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8207, Val Acc: 0.7464
  Time: 7.81s

[419/510]

============================================================
Experiment: FGSM_ep5_input_perturbation_sigma0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.3216, Val Acc: 0.3158
  Time: 7.75s

[420/510]

============================================================
Experiment: FGSM_ep5_input_perturbation_sigma1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.1249, Val Acc: 0.1244
  Time: 7.76s

[421/510]

============================================================
Experiment: FGSM_ep5_test_time_augmentation_num_augmentations1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8351, Val Acc: 0.7758
  Time: 7.83s

[422/510]

============================================================
Experiment: FGSM_ep5_test_time_augmentation_num_augmentations3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8733, Val Acc: 0.8092
  Time: 8.34s

[423/510]

============================================================
Experiment: FGSM_ep5_test_time_augmentation_num_augmentations5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8717, Val Acc: 0.7988
  Time: 8.91s

[424/510]

============================================================
Experiment: FGSM_ep5_test_time_augmentation_num_augmentations7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8917, Val Acc: 0.8132
  Time: 9.56s

[425/510]

============================================================
Experiment: FGSM_ep5_test_time_augmentation_num_augmentations10
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8935, Val Acc: 0.8104
  Time: 10.36s

[426/510]

============================================================
Experiment: FGSM_ep5_temperature_scaled_temp1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9348, Val Acc: 0.8472
  Time: 7.76s

[427/510]

============================================================
Experiment: FGSM_ep5_temperature_scaled_temp1.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9321, Val Acc: 0.8482
  Time: 7.81s

[428/510]

============================================================
Experiment: FGSM_ep5_temperature_scaled_temp2.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9330, Val Acc: 0.8474
  Time: 7.75s

[429/510]

============================================================
Experiment: FGSM_ep5_temperature_scaled_temp3.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9373, Val Acc: 0.8484
  Time: 7.74s

[430/510]

============================================================
Experiment: FGSM_ep5_temperature_scaled_temp5.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9346, Val Acc: 0.8474
  Time: 7.81s

[431/510]

============================================================
Experiment: FGSM_ep5_temperature_scaled_temp10.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9282, Val Acc: 0.8464
  Time: 7.75s

[432/510]

============================================================
Experiment: FGSM_ep5_response_limited_topk_top_k1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9330, Val Acc: 0.8482
  Time: 7.77s

[433/510]

============================================================
Experiment: FGSM_ep5_response_limited_topk_top_k2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9388, Val Acc: 0.8486
  Time: 7.82s

[434/510]

============================================================
Experiment: FGSM_ep5_response_limited_topk_top_k3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9308, Val Acc: 0.8480
  Time: 7.75s

[435/510]

============================================================
Experiment: FGSM_ep5_response_limited_topk_top_k4
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9317, Val Acc: 0.8482
  Time: 7.75s

[436/510]

============================================================
Experiment: FGSM_ep5_response_limited_topk_top_k5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9381, Val Acc: 0.8488
  Time: 7.81s

[437/510]

============================================================
Experiment: FGSM_ep5_response_limited_hard_hard_labelTrue
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9389, Val Acc: 0.8482
  Time: 7.74s

[438/510]

============================================================
Experiment: FGSM_ep5_adaptive_noise_alpha0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9391, Val Acc: 0.8476
  Time: 7.75s

[439/510]

============================================================
Experiment: FGSM_ep5_adaptive_noise_alpha0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9281, Val Acc: 0.8452
  Time: 7.81s

[440/510]

============================================================
Experiment: FGSM_ep5_adaptive_noise_alpha0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9367, Val Acc: 0.8470
  Time: 7.74s

[441/510]

============================================================
Experiment: FGSM_ep5_adaptive_noise_alpha0.7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9241, Val Acc: 0.8414
  Time: 7.83s

[442/510]

============================================================
Experiment: FGSM_ep5_adaptive_noise_alpha1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 5 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9155, Val Acc: 0.8356
  Time: 7.75s

[443/510]

============================================================
Experiment: FGSM_ep7_none_
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9432, Val Acc: 0.8434
  Time: 10.58s

[444/510]

============================================================
Experiment: FGSM_ep7_output_perturbation_scale0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9385, Val Acc: 0.8370
  Time: 10.63s

[445/510]

============================================================
Experiment: FGSM_ep7_output_perturbation_scale0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9383, Val Acc: 0.8374
  Time: 10.56s

[446/510]

============================================================
Experiment: FGSM_ep7_output_perturbation_scale0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9391, Val Acc: 0.8380
  Time: 10.65s

[447/510]

============================================================
Experiment: FGSM_ep7_output_perturbation_scale0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9355, Val Acc: 0.8368
  Time: 10.57s

[448/510]

============================================================
Experiment: FGSM_ep7_output_perturbation_scale0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9372, Val Acc: 0.8356
  Time: 10.65s

[449/510]

============================================================
Experiment: FGSM_ep7_input_perturbation_sigma0.01
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9426, Val Acc: 0.8432
  Time: 10.57s

[450/510]

============================================================
Experiment: FGSM_ep7_input_perturbation_sigma0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9385, Val Acc: 0.8386
  Time: 10.58s

[451/510]

============================================================
Experiment: FGSM_ep7_input_perturbation_sigma0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9246, Val Acc: 0.8260
  Time: 10.66s

[452/510]

============================================================
Experiment: FGSM_ep7_input_perturbation_sigma0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8289, Val Acc: 0.7476
  Time: 10.58s

[453/510]

============================================================
Experiment: FGSM_ep7_input_perturbation_sigma0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.3446, Val Acc: 0.3360
  Time: 10.67s

[454/510]

============================================================
Experiment: FGSM_ep7_input_perturbation_sigma1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.1184, Val Acc: 0.1178
  Time: 10.57s

[455/510]

============================================================
Experiment: FGSM_ep7_test_time_augmentation_num_augmentations1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8256, Val Acc: 0.7544
  Time: 10.64s

[456/510]

============================================================
Experiment: FGSM_ep7_test_time_augmentation_num_augmentations3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8823, Val Acc: 0.8038
  Time: 11.17s

[457/510]

============================================================
Experiment: FGSM_ep7_test_time_augmentation_num_augmentations5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8821, Val Acc: 0.8028
  Time: 11.81s

[458/510]

============================================================
Experiment: FGSM_ep7_test_time_augmentation_num_augmentations7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8909, Val Acc: 0.8032
  Time: 12.32s

[459/510]

============================================================
Experiment: FGSM_ep7_test_time_augmentation_num_augmentations10
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9014, Val Acc: 0.8190
  Time: 13.26s

[460/510]

============================================================
Experiment: FGSM_ep7_temperature_scaled_temp1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9420, Val Acc: 0.8390
  Time: 10.57s

[461/510]

============================================================
Experiment: FGSM_ep7_temperature_scaled_temp1.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9426, Val Acc: 0.8404
  Time: 10.57s

[462/510]

============================================================
Experiment: FGSM_ep7_temperature_scaled_temp2.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9407, Val Acc: 0.8396
  Time: 10.64s

[463/510]

============================================================
Experiment: FGSM_ep7_temperature_scaled_temp3.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9407, Val Acc: 0.8380
  Time: 10.57s

[464/510]

============================================================
Experiment: FGSM_ep7_temperature_scaled_temp5.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9402, Val Acc: 0.8396
  Time: 10.64s

[465/510]

============================================================
Experiment: FGSM_ep7_temperature_scaled_temp10.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9407, Val Acc: 0.8392
  Time: 10.58s

[466/510]

============================================================
Experiment: FGSM_ep7_response_limited_topk_top_k1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9410, Val Acc: 0.8386
  Time: 10.65s

[467/510]

============================================================
Experiment: FGSM_ep7_response_limited_topk_top_k2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9430, Val Acc: 0.8432
  Time: 10.58s

[468/510]

============================================================
Experiment: FGSM_ep7_response_limited_topk_top_k3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9429, Val Acc: 0.8430
  Time: 10.66s

[469/510]

============================================================
Experiment: FGSM_ep7_response_limited_topk_top_k4
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9427, Val Acc: 0.8414
  Time: 10.58s

[470/510]

============================================================
Experiment: FGSM_ep7_response_limited_topk_top_k5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9432, Val Acc: 0.8420
  Time: 10.65s

[471/510]

============================================================
Experiment: FGSM_ep7_response_limited_hard_hard_labelTrue
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9431, Val Acc: 0.8422
  Time: 10.58s

[472/510]

============================================================
Experiment: FGSM_ep7_adaptive_noise_alpha0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9426, Val Acc: 0.8434
  Time: 10.58s

[473/510]

============================================================
Experiment: FGSM_ep7_adaptive_noise_alpha0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9418, Val Acc: 0.8424
  Time: 10.64s

[474/510]

============================================================
Experiment: FGSM_ep7_adaptive_noise_alpha0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9425, Val Acc: 0.8422
  Time: 10.59s

[475/510]

============================================================
Experiment: FGSM_ep7_adaptive_noise_alpha0.7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9392, Val Acc: 0.8396
  Time: 10.66s

[476/510]

============================================================
Experiment: FGSM_ep7_adaptive_noise_alpha1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 7 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9326, Val Acc: 0.8322
  Time: 10.60s

[477/510]

============================================================
Experiment: FGSM_ep10_none_
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9457, Val Acc: 0.8356
  Time: 14.88s

[478/510]

============================================================
Experiment: FGSM_ep10_output_perturbation_scale0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9475, Val Acc: 0.8344
  Time: 14.82s

[479/510]

============================================================
Experiment: FGSM_ep10_output_perturbation_scale0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9459, Val Acc: 0.8284
  Time: 14.89s

[480/510]

============================================================
Experiment: FGSM_ep10_output_perturbation_scale0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9466, Val Acc: 0.8306
  Time: 14.89s

[481/510]

============================================================
Experiment: FGSM_ep10_output_perturbation_scale0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9452, Val Acc: 0.8354
  Time: 14.83s

[482/510]

============================================================
Experiment: FGSM_ep10_output_perturbation_scale0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9396, Val Acc: 0.8226
  Time: 14.88s

[483/510]

============================================================
Experiment: FGSM_ep10_input_perturbation_sigma0.01
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9447, Val Acc: 0.8366
  Time: 14.84s

[484/510]

============================================================
Experiment: FGSM_ep10_input_perturbation_sigma0.05
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9433, Val Acc: 0.8240
  Time: 14.91s

[485/510]

============================================================
Experiment: FGSM_ep10_input_perturbation_sigma0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9303, Val Acc: 0.8218
  Time: 14.90s

[486/510]

============================================================
Experiment: FGSM_ep10_input_perturbation_sigma0.2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8381, Val Acc: 0.7438
  Time: 14.82s

[487/510]

============================================================
Experiment: FGSM_ep10_input_perturbation_sigma0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.3666, Val Acc: 0.3536
  Time: 14.90s

[488/510]

============================================================
Experiment: FGSM_ep10_input_perturbation_sigma1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.1172, Val Acc: 0.1178
  Time: 14.90s

[489/510]

============================================================
Experiment: FGSM_ep10_test_time_augmentation_num_augmentations1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8357, Val Acc: 0.7628
  Time: 14.83s

[490/510]

============================================================
Experiment: FGSM_ep10_test_time_augmentation_num_augmentations3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8756, Val Acc: 0.7900
  Time: 15.47s

[491/510]

============================================================
Experiment: FGSM_ep10_test_time_augmentation_num_augmentations5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8922, Val Acc: 0.7954
  Time: 15.98s

[492/510]

============================================================
Experiment: FGSM_ep10_test_time_augmentation_num_augmentations7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8992, Val Acc: 0.8072
  Time: 16.63s

[493/510]

============================================================
Experiment: FGSM_ep10_test_time_augmentation_num_augmentations10
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.8954, Val Acc: 0.8060
  Time: 17.50s

[494/510]

============================================================
Experiment: FGSM_ep10_temperature_scaled_temp1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9475, Val Acc: 0.8346
  Time: 14.84s

[495/510]

============================================================
Experiment: FGSM_ep10_temperature_scaled_temp1.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9473, Val Acc: 0.8304
  Time: 14.88s

[496/510]

============================================================
Experiment: FGSM_ep10_temperature_scaled_temp2.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9462, Val Acc: 0.8298
  Time: 14.82s

[497/510]

============================================================
Experiment: FGSM_ep10_temperature_scaled_temp3.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9467, Val Acc: 0.8304
  Time: 14.86s

[498/510]

============================================================
Experiment: FGSM_ep10_temperature_scaled_temp5.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9475, Val Acc: 0.8318
  Time: 14.90s

[499/510]

============================================================
Experiment: FGSM_ep10_temperature_scaled_temp10.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9436, Val Acc: 0.8382
  Time: 14.80s

[500/510]

============================================================
Experiment: FGSM_ep10_response_limited_topk_top_k1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9454, Val Acc: 0.8352
  Time: 14.88s

[501/510]

============================================================
Experiment: FGSM_ep10_response_limited_topk_top_k2
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9465, Val Acc: 0.8298
  Time: 14.82s

[502/510]

============================================================
Experiment: FGSM_ep10_response_limited_topk_top_k3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9467, Val Acc: 0.8280
  Time: 14.87s

[503/510]

============================================================
Experiment: FGSM_ep10_response_limited_topk_top_k4
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9474, Val Acc: 0.8328
  Time: 14.90s

[504/510]

============================================================
Experiment: FGSM_ep10_response_limited_topk_top_k5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9465, Val Acc: 0.8292
  Time: 14.83s

[505/510]

============================================================
Experiment: FGSM_ep10_response_limited_hard_hard_labelTrue
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9466, Val Acc: 0.8302
  Time: 14.88s

[506/510]

============================================================
Experiment: FGSM_ep10_adaptive_noise_alpha0.1
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9468, Val Acc: 0.8306
  Time: 14.92s

[507/510]

============================================================
Experiment: FGSM_ep10_adaptive_noise_alpha0.3
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9456, Val Acc: 0.8356
  Time: 14.84s

[508/510]

============================================================
Experiment: FGSM_ep10_adaptive_noise_alpha0.5
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9453, Val Acc: 0.8322
  Time: 14.91s

[509/510]

============================================================
Experiment: FGSM_ep10_adaptive_noise_alpha0.7
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9460, Val Acc: 0.8294
  Time: 14.84s

[510/510]

============================================================
Experiment: FGSM_ep10_adaptive_noise_alpha1.0
============================================================
Loaded model from ./target_model.pt -- hash: 0CCE0F932C863D6648E0.
Fine-tuning with FGSM for 10 epochs...
Evaluating utility...
Evaluating privacy...
Evaluating robustness...

Results:
  Train Acc: 0.9418, Val Acc: 0.8332
  Time: 14.89s

Summary saved to: ./benchmark_results/summary.csv

--- Top 5 by Validation Accuracy ---
                               experiment_id  val_acc  train_acc
138  BASIC_ep10_output_perturbation_scale0.1   0.8932    0.99415
162  BASIC_ep10_response_limited_topk_top_k4   0.8924    0.99515
140  BASIC_ep10_output_perturbation_scale0.3   0.8916    0.99635
165       BASIC_ep10_adaptive_noise_alpha0.1   0.8916    0.99440
136                         BASIC_ep10_none_   0.8914    0.99545

--- Top 5 by Privacy (Lowest MIA Accuracy) ---
                             experiment_id  val_acc  mia_avg_acc
249    PGD_ep5_input_perturbation_sigma1.0   0.2102     0.489909
384   FGSM_ep3_input_perturbation_sigma0.5   0.3076     0.490234
44   BASIC_ep3_input_perturbation_sigma0.5   0.3468     0.495117
283    PGD_ep7_input_perturbation_sigma1.0   0.2010     0.495117
487  FGSM_ep10_input_perturbation_sigma1.0   0.1178     0.495117

--- Top 5 by Robustness (Highest Adversarial Accuracy) ---
                                         experiment_id  val_acc  adv_robust_acc
81   BASIC_ep5_test_time_augmentation_num_augmentat...   0.8688          0.8475
114  BASIC_ep7_test_time_augmentation_num_augmentat...   0.8446          0.8475
48   BASIC_ep3_test_time_augmentation_num_augmentat...   0.8736          0.8450
116  BASIC_ep7_test_time_augmentation_num_augmentat...   0.8730          0.8400
152  BASIC_ep10_test_time_augmentation_num_augmenta...   0.8808          0.8350

============================================================
BENCHMARK COMPLETE
============================================================
